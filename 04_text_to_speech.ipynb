{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dce7fe3-48a1-4d90-a0d5-93bd55c54c1a",
   "metadata": {},
   "source": [
    "Text-to-speech (TTS) is the task of creating natural-sounding speech from text, where the speech can be generated in multiple languages and for multiple speakers. Several text-to-speech models are currently available in ðŸ¤— Transformers, such as Bark, MMS, VITS and SpeechT5.\n",
    "\n",
    "You can easily generate audio using the \"text-to-audio\" pipeline (or its alias - \"text-to-speech\"). Some models, like Bark, can also be conditioned to generate non-verbal communications such as laughing, sighing and crying, or even add music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf880a0-d66f-4116-aa99-0688edca7493",
   "metadata": {},
   "source": [
    "Hereâ€™s an example of how you would use the \"text-to-speech\" pipeline with Bark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88337116-ac1d-4f78-870c-0e9c8bae4685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from IPython.display import Audio\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\")\n",
    "text = \"[clears throat] This is a test ... and I just took a long pause.\"\n",
    "output = pipe(text)\n",
    "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01320809-7970-452e-bc9a-0a677fe44a14",
   "metadata": {},
   "source": [
    "If you are looking to fine-tune a TTS model, the only text-to-speech models currently available in ðŸ¤— Transformers are SpeechT5 and FastSpeech2Conformer, though more will be added in the future. SpeechT5 is pre-trained on a combination of speech-to-text and text-to-speech data, allowing it to learn a unified space of hidden representations shared by both text and speech. This means that the same pre-trained model can be fine-tuned for different tasks. Furthermore, SpeechT5 supports multiple speakers through x-vector speaker embeddings.\n",
    "\n",
    "The remainder of this guide illustrates how to:\n",
    "1. Fine-tune SpeechT5 that was originally trained on English speech on the Dutch (nl) language subset of the VoxPopuli dataset.\n",
    "2. Use your refined model for inference in one of two ways: using a pipeline or directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e4d8b-bc7c-4af4-a8fa-8975c005c47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
