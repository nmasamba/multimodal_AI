{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dce7fe3-48a1-4d90-a0d5-93bd55c54c1a",
   "metadata": {},
   "source": [
    "Text-to-speech (TTS) is the task of creating natural-sounding speech from text, where the speech can be generated in multiple languages and for multiple speakers. Several text-to-speech models are currently available in 🤗 Transformers, such as Bark, MMS, VITS and SpeechT5.\n",
    "\n",
    "You can easily generate audio using the \"text-to-audio\" pipeline (or its alias - \"text-to-speech\"). Some models, like Bark, can also be conditioned to generate non-verbal communications such as laughing, sighing and crying, or even add music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf880a0-d66f-4116-aa99-0688edca7493",
   "metadata": {},
   "source": [
    "Here’s an example of how you would use the \"text-to-speech\" pipeline with Bark:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a659f-db46-4fb2-929a-21844f43454f",
   "metadata": {},
   "source": [
    "```\n",
    "from transformers import pipeline\n",
    "from IPython.display import Audio\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\")\n",
    "text = \"[clears throat] This is a test ... and I just took a long pause.\"\n",
    "output = pipe(text)\n",
    "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01320809-7970-452e-bc9a-0a677fe44a14",
   "metadata": {},
   "source": [
    "If you are looking to fine-tune a TTS model, the only text-to-speech models currently available in 🤗 Transformers are SpeechT5 and FastSpeech2Conformer, though more will be added in the future. SpeechT5 is pre-trained on a combination of speech-to-text and text-to-speech data, allowing it to learn a unified space of hidden representations shared by both text and speech. This means that the same pre-trained model can be fine-tuned for different tasks. Furthermore, SpeechT5 supports multiple speakers through x-vector speaker embeddings.\n",
    "\n",
    "The remainder of this guide illustrates how to:\n",
    "1. Fine-tune SpeechT5 that was originally trained on English speech on the Dutch (nl) language subset of the VoxPopuli dataset.\n",
    "2. Use your refined model for inference in one of two ways: using a pipeline or directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c757716-8f6e-4cfe-ab7f-0af57ca12145",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61c4e11-bb04-4c69-af50-207bbcb0f9d7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (2.15.0)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: soundfile in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (0.12.1)\n",
      "Collecting soundfile\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: speechbrain in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (1.0.2)\n",
      "Requirement already satisfied: accelerate in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (1.3.0)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (1.22.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-19.0.1.tar.gz (1.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (2.0.3)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: xxhash in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: hyperpyyaml in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from speechbrain) (1.2.2)\n",
      "Requirement already satisfied: joblib in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from speechbrain) (1.2.0)\n",
      "Requirement already satisfied: scipy in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from speechbrain) (1.7.3)\n",
      "Requirement already satisfied: sentencepiece in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from speechbrain) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.9 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from speechbrain) (2.2.2)\n",
      "Requirement already satisfied: torchaudio in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from speechbrain) (2.2.2)\n",
      "Requirement already satisfied: psutil in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: pycparser in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from hyperpyyaml->speechbrain) (0.18.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from jinja2->torch>=1.9->speechbrain) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
      "Using cached datasets-3.4.1-py3-none-any.whl (487 kB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-macosx_10_9_x86_64.whl (1.1 MB)\n",
      "Using cached accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: pyarrow\n",
      "  Building wheel for pyarrow (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyarrow \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[784 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/orc.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/conftest.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_generated_version.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/benchmark.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute_docstrings.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/ipc.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/util.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/flight.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/cffi.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/substrait.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/types.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/dataset.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/cuda.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/feather.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/pandas_compat.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/fs.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/acero.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/csv.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/jvm.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/json.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/compute.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing pyarrow.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to pyarrow.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to pyarrow.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to pyarrow.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m ERROR setuptools_scm._file_finders.git listing git files failed - pretending there aren't any\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '../LICENSE.txt'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '../NOTICE.txt'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.so' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '#*' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.git*' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m no previously-included directories found matching '.asv'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.includes' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.includes' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.includes' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.includes' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.includes' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.interchange' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.interchange' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.interchange' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.interchange' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.interchange' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.src.arrow.python' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.src.arrow.python' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.src.arrow.python' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.src.arrow.python' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.src.arrow.python' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.src.arrow.python.vendored' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.src.arrow.python.vendored' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.src.arrow.python.vendored' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.src.arrow.python.vendored' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.src.arrow.python.vendored' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.feather' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.feather' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.feather' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.feather' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.feather' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.orc' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.orc' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.orc' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.orc' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.orc' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.interchange' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.interchange' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.interchange' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.interchange' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.interchange' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-build-env-sgxkxvvx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.vendored' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.vendored' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.vendored' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.vendored' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.vendored' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/__init__.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_acero.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_acero.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_azurefs.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_csv.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_csv.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_cuda.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_cuda.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_orc.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet_encryption.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dlpack.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_feather.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_flight.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_fs.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_fs.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_gcsfs.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_hdfs.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_json.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_json.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_orc.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_orc.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet_encryption.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet_encryption.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_pyarrow_cpp_tests.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_pyarrow_cpp_tests.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_s3fs.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_substrait.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/array.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/benchmark.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/builder.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/compat.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/config.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/device.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/error.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/gandiva.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/io.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/ipc.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/lib.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/lib.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/memory.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/pandas-shim.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/public-api.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/scalar.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/table.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tensor.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/types.pxi -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/__init__.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/common.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_acero.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_cuda.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_dataset.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_dataset_parquet.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_feather.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_flight.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_fs.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_python.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_substrait.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libgandiva.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libparquet_encryption.pxd -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/buffer.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/column.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/dataframe.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/from_dataframe.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/core.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/encryption.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/CMakeLists.txt -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/api.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_pandas.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_pandas.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_python_internal.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/async.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/benchmark.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/benchmark.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/common.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/common.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/csv.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/csv.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/datetime.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/datetime.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/decimal.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/decimal.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/deserialize.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/deserialize.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/extension_type.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/extension_type.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/filesystem.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/filesystem.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/flight.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/flight.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/gdb.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/gdb.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/helpers.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/helpers.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/inference.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/inference.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/io.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/io.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/ipc.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/ipc.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/iterators.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_convert.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_convert.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_init.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_init.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_internal.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_interop.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_to_arrow.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_to_arrow.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/parquet_encryption.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/parquet_encryption.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pch.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/platform.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow_api.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow_lib.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_test.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_test.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_to_arrow.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_to_arrow.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/serialize.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/serialize.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/type_traits.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/udf.cc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/udf.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/visibility.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/vendored/CMakeLists.txt -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/vendored/pythoncapi_compat.h -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_16597.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_39313.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_7980.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/bound_function_visit_strings.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/conftest.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/extensions.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pandas_examples.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pandas_threaded_import.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pyarrow_cython_example.pyx -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/read_record_batch.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/strategies.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_acero.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_adhoc_memory_leak.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_array.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_builder.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cffi.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_compute.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_convert_builtin.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cpp_internals.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_csv.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cuda.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cuda_numba_interop.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cython.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dataset.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dataset_encryption.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_deprecations.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_device.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dlpack.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_exec_plan.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_extension_type.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_feather.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_flight.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_flight_async.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_fs.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_gandiva.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_gdb.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_io.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_ipc.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_json.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_jvm.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_memory.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_misc.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_orc.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_pandas.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_scalars.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_schema.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_sparse_tensor.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_strategies.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_substrait.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_table.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_tensor.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_types.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_udf.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_util.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_without_numpy.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/util.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/wsgi_examples.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/feather\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/feather/v0.17.0.version.2-compression.lz4.feather -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/feather\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/README.md -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.jsn.gz -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.orc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.test1.jsn.gz -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.test1.orc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.jsn.gz -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.orc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/decimal.jsn.gz -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/decimal.orc -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.all-named-index.parquet -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.column-metadata-handling.parquet -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.parquet -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.some-named-index.parquet -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/test_conversion.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/test_interchange_spec.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/common.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/conftest.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/encryption.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_basic.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_compliant_nested_type.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_data_types.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_dataset.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_datetime.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_encryption.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_metadata.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_pandas.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_parquet_file.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_parquet_writer.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/docscrape.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/version.py -> build/lib.macosx-10.9-x86_64-cpython-310/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-install-m_ti1_gq/pyarrow_6c1be7bbb7ab484195738f622fa19f25/build/temp.macosx-10.9-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m -- Running cmake for PyArrow\n",
      "  \u001b[31m   \u001b[0m cmake -DCMAKE_INSTALL_PREFIX=/private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-install-m_ti1_gq/pyarrow_6c1be7bbb7ab484195738f622fa19f25/build/lib.macosx-10.9-x86_64-cpython-310/pyarrow -DPYTHON_EXECUTABLE=/Users/nm/opt/anaconda3/envs/nlp/bin/python -DPython3_EXECUTABLE=/Users/nm/opt/anaconda3/envs/nlp/bin/python -DPYARROW_CXXFLAGS= -DPYARROW_BUNDLE_ARROW_CPP=off -DPYARROW_BUNDLE_CYTHON_CPP=off -DPYARROW_GENERATE_COVERAGE=off -DCMAKE_BUILD_TYPE=release /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-install-m_ti1_gq/pyarrow_6c1be7bbb7ab484195738f622fa19f25\n",
      "  \u001b[31m   \u001b[0m error: command 'cmake' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pyarrow\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build pyarrow\n",
      "\u001b[31mERROR: Could not build wheels for pyarrow, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-req-build-jqbot2ej\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /private/var/folders/m0/q0rh1ws5051_6t97sbr207tm0000gn/T/pip-req-build-jqbot2ej\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 63c31165306226798c1353ca93701c7e11ce4e4f\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers==4.50.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers==4.50.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers==4.50.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers==4.50.0.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers==4.50.0.dev0) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets soundfile speechbrain accelerate\n",
    "\n",
    "# Install 🤗Transformers from source as not all the SpeechT5 features have been merged into an official release\n",
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfa3993-6be1-4a90-b121-37d4a9c55704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n",
      "zsh:1: command not found: rocm-smi\n"
     ]
    }
   ],
   "source": [
    "# To follow this guide you will need a GPU\n",
    "\n",
    "# If you’re working in a notebook, run the following line to check if NVIDIA GPU available\n",
    "#!nvidia-smi\n",
    "\n",
    "# Or for AMD GPU\n",
    "#!rocm-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf34fa1-398b-4915-ba9e-12e26fb96d84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "/Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <A549E5FA-1487-3474-A747-4913D621982E> /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <A84DFEFF-287E-3B94-A7DB-731FA5F9CBBC> /Users/nm/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-03-19 16:35:31.871494: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nmodule 'torch.distributed' has no attribute 'device_mesh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/utils/import_utils.py:1949\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/__init__.py:49\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     37\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     logging,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioClassificationPipeline\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomatic_speech_recognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutomaticSpeechRecognitionPipeline\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/audio_classification.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_end_docstrings, is_torch_available, is_torchaudio_available, logging\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline, build_pipeline_init_args\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/base.py:69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py:756\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m old_param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m old_param\u001b[38;5;241m.\u001b[39mis_contiguous(), casting_dtype\n\u001b[1;32m    740\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_state_dict_into_meta_model\u001b[39m(\n\u001b[1;32m    742\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    743\u001b[0m     state_dict: Dict,\n\u001b[1;32m    744\u001b[0m     shard_file: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    745\u001b[0m     expected_keys: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    746\u001b[0m     reverse_renaming_mapping: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    747\u001b[0m     device_map: Optional[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    748\u001b[0m     disk_offload_folder: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    749\u001b[0m     disk_offload_index: Optional[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    750\u001b[0m     cpu_offload_folder: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    751\u001b[0m     cpu_offload_index: Optional[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    752\u001b[0m     hf_quantizer: Optional[HfQuantizer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    753\u001b[0m     is_safetensors: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    754\u001b[0m     keep_in_fp32_modules: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    755\u001b[0m     unexpected_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# passing `unexpected` for cleanup from quantization items\u001b[39;00m\n\u001b[0;32m--> 756\u001b[0m     device_mesh: Optional[\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241m.\u001b[39mDeviceMesh] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    757\u001b[0m     weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    758\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Dict], Optional[Dict]]:\n\u001b[1;32m    759\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load parameters from `meta_state_dict` into the model. The parameters of the `meta_state_dict` are on the meta\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    device in order to easily infer the shapes and dtypes that they will have. Then proper parameters are then loaded\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m    from `shard_file`, which is the actual state dict file on disk.\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;124;03m    This function takes care of correctly casting dtypes, devices, and sharding tensors in case of tensor parallelism.\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.distributed' has no attribute 'device_mesh'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_backend\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeechbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifiers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncoderClassifier\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline, SpeechT5Processor, SpeechT5ForTextToSpeech, Seq2SeqTrainingArguments\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/utils/import_utils.py:1937\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1935\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1937\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1938\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/utils/import_utils.py:1951\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1952\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1953\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1954\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nmodule 'torch.distributed' has no attribute 'device_mesh'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, List, Union\n",
    "from accelerate.test_utils.testing import get_backend\n",
    "from speechbrain.inference.classifiers import EncoderClassifier\n",
    "from transformers import pipeline, SpeechT5Processor, SpeechT5ForTextToSpeech, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c7df51-c5be-422e-8350-80de49858a9a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0892b50-f61d-468c-98a7-92a76594f1f7",
   "metadata": {},
   "source": [
    "VoxPopuli is a large-scale multilingual speech corpus consisting of data sourced from 2009-2020 European Parliament event recordings. It contains labelled audio-transcription data for 15 European languages. In this guide, we are using the Dutch language subset, feel free to pick another subset.\n",
    "\n",
    "Note that VoxPopuli or any other automated speech recognition (ASR) dataset may not be the most suitable option for training TTS models. The features that make it beneficial for ASR, such as excessive background noise, are typically undesirable in TTS. However, finding top-quality, multilingual, and multi-speaker TTS datasets can be quite challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a23d5-ab04-4b40-a52a-ca5246d5533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "# Check len == 20968 examples\n",
    "dataset = load_dataset(\"facebook/voxpopuli\", \"nl\", split=\"train\")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bba98f-3595-41c1-a10e-1de6e02b51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpeechT5 expects audio data to have a sampling rate of 16 kHz\n",
    "# Make sure the examples in the dataset meet the requirement of 16kHz sampling rate\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4d384-32ff-4227-90f3-5fbcf7a80531",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9609121-b659-4a5e-b41b-86b7b3d0dbde",
   "metadata": {},
   "source": [
    "## Text Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f24b0f-bab1-49a7-8179-9d12bdf58c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load appropriate tokenizer and clean up text\n",
    "checkpoint = \"microsoft/speecht5_tts\"\n",
    "processor = SpeechT5Processor.from_pretrained(checkpoint)\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a32d59-ab0b-44aa-b015-f2696c56fb50",
   "metadata": {},
   "source": [
    "The dataset examples contain ```raw_text``` and ```normalized_text``` features. When deciding which feature to use as the text input, consider that the SpeechT5 tokenizer doesn’t have any tokens for numbers. In ```normalized_text``` the numbers are written out as text. Thus, it is a better fit, and it is recommended to use ```normalized_text``` as input text.\n",
    "\n",
    "Because SpeechT5 was trained on the English language, it may not recognize certain characters in the Dutch dataset. If left as is, these characters will be converted to ```<unk>``` tokens. However, in Dutch, certain characters like à are used to stress syllables. In order to preserve the meaning of the text, we can replace this character with a regular a.\n",
    "\n",
    "To identify unsupported tokens, extract all unique characters in the dataset using the SpeechT5Tokenizer which works with characters as tokens. To do this, write the ```extract_all_chars``` mapping function that concatenates the transcriptions from all examples into one string and converts it to a set of characters. Make sure to set ```batched=True``` and ```batch_size=-1``` in ```dataset.map()``` so that all transcriptions are available at once for the mapping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00946e-b95e-474a-88df-a2230d214a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"normalized_text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "\n",
    "vocabs = dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "\n",
    "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
    "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e11b91-89ae-49d2-be79-c6def731230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify unrecognised characters\n",
    "print(dataset_vocab - tokenizer_vocab)\n",
    "\n",
    "# Handle the unsupported characters identified in the previous step (manually in this case)\n",
    "replacements = [\n",
    "    (\"à\", \"a\"),\n",
    "    (\"ç\", \"c\"),\n",
    "    (\"è\", \"e\"),\n",
    "    (\"ë\", \"e\"),\n",
    "    (\"í\", \"i\"),\n",
    "    (\"ï\", \"i\"),\n",
    "    (\"ö\", \"o\"),\n",
    "    (\"ü\", \"u\"),\n",
    "]\n",
    "\n",
    "\n",
    "def cleanup_text(inputs):\n",
    "    for src, dst in replacements:\n",
    "        inputs[\"normalized_text\"] = inputs[\"normalized_text\"].replace(src, dst)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "dataset = dataset.map(cleanup_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594b3e9-5345-43d6-b6e4-8fc3cfe4d594",
   "metadata": {},
   "source": [
    "## Audio Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583aa51-e5ed-4c08-b4cf-dbe1b5df0ea5",
   "metadata": {},
   "source": [
    "### Multiple speaker identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70518946-5575-46be-b6fa-85745e559700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many speakers are represented in the dataset?\n",
    "speaker_counts = defaultdict(int)\n",
    "\n",
    "for speaker_id in dataset[\"speaker_id\"]:\n",
    "    speaker_counts[speaker_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2800bdd-bc95-414f-9221-587ea1a0b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many examples are there for each speaker?\n",
    "plt.figure()\n",
    "plt.hist(speaker_counts.values(), bins=20)\n",
    "plt.ylabel(\"Speakers\")\n",
    "plt.xlabel(\"Examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67d65a-b4ea-4dc6-a748-37f54d119644",
   "metadata": {},
   "source": [
    "The histogram reveals that approximately one-third of the speakers in the dataset have fewer than 100 examples, while around ten speakers have more than 500 examples. To improve training efficiency and balance the dataset, we can limit the data to speakers with between 100 and 400 examples.\n",
    "\n",
    "You should be left with just under 10,000 examples from approximately 40 unique speakers, which should be sufficient.\n",
    "\n",
    "Note that some speakers with few examples may actually have more audio available if the examples are long. However, determining the total amount of audio for each speaker requires scanning through the entire dataset, which is a time-consuming process that involves loading and decoding each audio file. As such, we have chosen to skip this step here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47f526-6ef0-402e-b831-87f10b691861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_speaker(speaker_id):\n",
    "    return 100 <= speaker_counts[speaker_id] <= 400\n",
    "\n",
    "dataset = dataset.filter(select_speaker, input_columns=[\"speaker_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f038ac-9d5d-483c-bd29-5c5a710fb09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many speakers are left\n",
    "len(set(dataset[\"speaker_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7f63b-3540-4a82-b08a-fe6158eda08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many examples are left\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ccd57-e3ad-4bae-9369-54b80c9819de",
   "metadata": {},
   "source": [
    "### Multiple speaker embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b9ac1-f33e-4d4c-9310-5737e9473a5c",
   "metadata": {},
   "source": [
    "To enable the TTS model to differentiate between multiple speakers, you’ll need to create a speaker embedding for each example. The speaker embedding is an additional input into the model that captures a particular speaker’s voice characteristics. \n",
    "\n",
    "To generate these speaker embeddings, use the pre-trained ```spkrec-xvect-voxceleb``` model from SpeechBrain. It’s important to note that the ```spkrec-xvect-voxceleb``` model was trained on English speech from the VoxCeleb dataset, whereas the training examples in this guide are in Dutch. While we believe that this model will still generate reasonable speaker embeddings for our Dutch dataset, this assumption may not hold true in all cases.\n",
    "\n",
    "For optimal results, we recommend training an X-vector model on the target speech first. This will ensure that the model is better able to capture the unique voice characteristics present in the Dutch language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abef587-fbc5-4b0a-9fb7-28c59fe3482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
    "device, _, _ = get_backend() # automatically detects the underlying device type (CUDA, CPU, XPU, MPS, etc.)\n",
    "speaker_model = EncoderClassifier.from_hparams(\n",
    "    source=spk_model_name,\n",
    "    run_opts={\"device\": device},\n",
    "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
    ")\n",
    "\n",
    "\n",
    "def create_speaker_embedding(waveform):\n",
    "    \"\"\"\n",
    "    Function input: audio waveform. \n",
    "    Function output: 512-element vector containing the corresponding speaker embedding.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
    "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
    "    return speaker_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a8992-a079-4ce1-b818-e97a3d0f5eda",
   "metadata": {},
   "source": [
    "## Final preprocessing step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7fef8e-b8ec-478b-a240-de76fb83d9af",
   "metadata": {},
   "source": [
    "Finally, let’s process the data into the format the model expects. Create a ```prepare_dataset``` function that takes in a single example and uses the SpeechT5Processor object to tokenise the input text and load the target audio into a log-mel spectrogram. It should also add the speaker embeddings as an additional input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff8498-9f06-4057-827b-ae53587f915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example = processor(\n",
    "        text=example[\"normalized_text\"],\n",
    "        audio_target=audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        return_attention_mask=False,\n",
    "    )\n",
    "\n",
    "    # strip off the batch dimension\n",
    "    example[\"labels\"] = example[\"labels\"][0]\n",
    "\n",
    "    # use SpeechBrain to obtain x-vector\n",
    "    example[\"speaker_embeddings\"] = create_speaker_embedding(audio[\"array\"])\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4e484-5659-4195-b202-a26fbc75275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect an example\n",
    "processed_example = prepare_dataset(dataset[0])\n",
    "print(\"\\n\"+list(processed_example.keys()))\n",
    "\n",
    "# Speaker embeddings should be a 512-element vector\n",
    "print(\"\\n\"+processed_example[\"speaker_embeddings\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b008e6e-b3bf-4af6-b8ee-af595bf69537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels should be a log-mel spectrogram with 80 mel bins\n",
    "plt.figure()\n",
    "plt.imshow(processed_example[\"labels\"].T)\n",
    "plt.xlabel(\"# mel bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cded9c-6648-4cc1-93e9-bd74b4300185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_too_long(input_ids):\n",
    "    \"\"\"\n",
    "    Remove those examples from the dataset are longer than the maximum input length \n",
    "    the model can handle. Model allows up to 600 tokens. Here, we only allow up to 200 tokens.\n",
    "    \"\"\"\n",
    "    input_length = len(input_ids)\n",
    "    return input_length < 200\n",
    "\n",
    "\n",
    "dataset = dataset.filter(is_not_too_long, input_columns=[\"input_ids\"])\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cea248-68b1-4d43-91dc-0e28df60dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all looks good, apply the processing function to the entire dataset\n",
    "# This will take between 5 and 10 minutes\n",
    "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542c305-1dea-463c-8b73-3b112fb95a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test split\n",
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f12721-6c14-41f8-9662-49f05f144fff",
   "metadata": {},
   "source": [
    "## Data collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ec31a-6fd9-4eef-949d-621ef2e0647a",
   "metadata": {},
   "source": [
    "In order to combine multiple examples into a batch, you need to define a custom data collator. This collator will pad shorter sequences with padding tokens, ensuring that all examples have the same length. For the spectrogram labels, the padded portions are replaced with the special value -100. This special value instructs the model to ignore that part of the spectrogram when calculating the spectrogram loss.\n",
    "\n",
    "Note that in SpeechT5, the input to the decoder part of the model is reduced by a factor 2. In other words, it throws away every other timestep from the target sequence. The decoder then predicts a sequence that is twice as long. Since the original target sequence length may be odd, the data collator makes sure to round the maximum length of the batch down to be a multiple of 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86073aa6-8f36-42b8-80e8-fb970d86e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class TTSDataCollatorWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n",
    "        label_features = [{\"input_values\": feature[\"labels\"]} for feature in features]\n",
    "        speaker_features = [feature[\"speaker_embeddings\"] for feature in features]\n",
    "\n",
    "        # collate the inputs and targets into a batch\n",
    "        batch = processor.pad(input_ids=input_ids, labels=label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        batch[\"labels\"] = batch[\"labels\"].masked_fill(batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100)\n",
    "\n",
    "        # not used during fine-tuning\n",
    "        del batch[\"decoder_attention_mask\"]\n",
    "\n",
    "        # round down target lengths to multiple of reduction factor\n",
    "        if model.config.reduction_factor > 1:\n",
    "            target_lengths = torch.tensor([len(feature[\"input_values\"]) for feature in label_features])\n",
    "            target_lengths = target_lengths.new(\n",
    "                [length - length % model.config.reduction_factor for length in target_lengths]\n",
    "            )\n",
    "            max_length = max(target_lengths)\n",
    "            batch[\"labels\"] = batch[\"labels\"][:, :max_length]\n",
    "\n",
    "        # also add in the speaker embeddings\n",
    "        batch[\"speaker_embeddings\"] = torch.tensor(speaker_features)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a4e07-030a-4431-b060-cca60ebfcf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = TTSDataCollatorWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531738f1-5a74-45c0-9c65-ea4b5cff0478",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b1f04-17f0-40aa-a0bc-8378536f57bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08d735-62f0-484a-89dc-f12b6cc20503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_cache is incompatible with gradient checkpointing\n",
    "# Disable for training\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba90087-8fec-4b1f-ba22-efd0ffa5a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training args\n",
    "# Note we're not defining eval metrics here; we'll only use the loss\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"speecht5_finetuned_voxpopuli_nl\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=2,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    label_names=[\"labels\"],\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13b0ad-e1f6-4105-aab3-19590fc71270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Trainer object\n",
    "# Pass training args, model, dataset, data collator to Trainer object\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f91103-778b-4fbd-9e95-bcc7ffc7f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call train on trainer object to fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0789ec-b0a1-411e-b90f-6e1ce6388389",
   "metadata": {},
   "source": [
    "Depending on your GPU, it is possible that you will encounter a CUDA “out-of-memory” error when you start training. In this case, you can reduce the ```per_device_train_batch_size``` incrementally by factors of 2 and increase ```gradient_accumulation_steps``` by 2x to compensate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723c6b5-0e77-4309-95ae-2aa595a55a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below if you want to save the checkpoint and use with a pipeline\n",
    "#processor.save_pretrained(\"DIR_OR_ACCOUNT_NAME/speecht5_finetuned_voxpopuli_nl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d9b923-59f2-4f57-ad49-f2ba2841e1ac",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46255c9f-b99b-4dd9-bd47-7743c2b1494e",
   "metadata": {},
   "source": [
    "## Inference using a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707af22-dd5e-4b60-b748-7058095b1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-to-speech\", model=\"speecht5_finetuned_voxpopuli_nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05786dba-bfa8-4c0e-a04c-fa9f4d9c7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a piece of text in Dutch that you want to translate\n",
    "text = \"hallo allemaal, ik praat nederlands. groetjes aan iedereen!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f4186-bfbe-4637-ab92-a48a7f6407cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpeechT5 pipeline requires a speech embedding\n",
    "# Get it from an example in the data set (arbitrarily chosen here)\n",
    "example = dataset[\"test\"][304]\n",
    "speaker_embeddings = torch.tensor(example[\"speaker_embeddings\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907c32e-b760-47b2-a673-0b20034be08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the text and speaker embeddings to the pipeline\n",
    "forward_params = {\"speaker_embeddings\": speaker_embeddings}\n",
    "output = pipe(text, forward_params=forward_params)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fef59-4923-445b-a2fb-4aa45e48860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to the resulting audio\n",
    "Audio(output['audio'], rate=output['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e39499-dcfd-45e9-a837-6bf93dbc3a19",
   "metadata": {},
   "source": [
    "## Manual inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444af002-e68c-4eef-86e1-39ab097ec991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"speecht5_finetuned_voxpopuli_nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a247090-bbdb-4d66-a188-465a7eae9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a speech embedding from a training example\n",
    "example = dataset[\"test\"][304]\n",
    "speaker_embeddings = torch.tensor(example[\"speaker_embeddings\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13842dd5-832a-4796-9100-ee9affc5fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some input text and tokenize it\n",
    "text = \"hallo allemaal, ik praat nederlands. groetjes aan iedereen!\"\n",
    "inputs = processor(text=text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e5c9a-4a10-4d1e-9d61-524bc8be6a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc07fb-8aaa-480e-a351-e290a6180879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: create and visualise spectrogram \n",
    "spectrogram = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(spectrogram.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97b607-ecef-413d-92b6-74c8a6cf569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the vocoder to turn text into sound\n",
    "with torch.no_grad():\n",
    "    speech = vocoder(spectrogram)\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "Audio(speech.numpy(), rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef8422d-bad8-442c-aa8c-471034c1c54b",
   "metadata": {},
   "source": [
    "# Final Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3411b0f4-de44-44e3-bbe7-98fbcd1abd84",
   "metadata": {},
   "source": [
    "From experience, obtaining satisfactory results from this model can be challenging. The quality of the speaker embeddings appears to be a significant factor. Since SpeechT5 was pre-trained with English x-vectors, it performs best when using English speaker embeddings. That said, the speech clearly is Dutch instead of English, and it does capture the voice characteristics of the speaker (compare to the original audio in the example). If the synthesized speech sounds poor, you can try the following:\n",
    "\n",
    "1. Try using a different speaker embedding example.\n",
    "2. Increasing the training duration is also likely to enhance the quality of the results.  \n",
    "3. Experiment with the model’s configuration. For example, try using config.reduction_factor = 1 to see if this improves the results.\n",
    "\n",
    "Finally, it is essential to consider ethical considerations. Although TTS technology has numerous useful applications, it may also be used for malicious purposes, such as impersonating someone’s voice without their knowledge or consent. Please use TTS judiciously and responsibly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503bebe-1257-4485-9a1d-fdbe8beabb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
