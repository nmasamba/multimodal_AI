{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dce7fe3-48a1-4d90-a0d5-93bd55c54c1a",
   "metadata": {},
   "source": [
    "Text-to-speech (TTS) is the task of creating natural-sounding speech from text, where the speech can be generated in multiple languages and for multiple speakers. Several text-to-speech models are currently available in ðŸ¤— Transformers, such as Bark, MMS, VITS and SpeechT5.\n",
    "\n",
    "You can easily generate audio using the \"text-to-audio\" pipeline (or its alias - \"text-to-speech\"). Some models, like Bark, can also be conditioned to generate non-verbal communications such as laughing, sighing and crying, or even add music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf880a0-d66f-4116-aa99-0688edca7493",
   "metadata": {},
   "source": [
    "Hereâ€™s an example of how you would use the \"text-to-speech\" pipeline with Bark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88337116-ac1d-4f78-870c-0e9c8bae4685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from IPython.display import Audio\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\")\n",
    "text = \"[clears throat] This is a test ... and I just took a long pause.\"\n",
    "output = pipe(text)\n",
    "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01320809-7970-452e-bc9a-0a677fe44a14",
   "metadata": {},
   "source": [
    "If you are looking to fine-tune a TTS model, the only text-to-speech models currently available in ðŸ¤— Transformers are SpeechT5 and FastSpeech2Conformer, though more will be added in the future. SpeechT5 is pre-trained on a combination of speech-to-text and text-to-speech data, allowing it to learn a unified space of hidden representations shared by both text and speech. This means that the same pre-trained model can be fine-tuned for different tasks. Furthermore, SpeechT5 supports multiple speakers through x-vector speaker embeddings.\n",
    "\n",
    "The remainder of this guide illustrates how to:\n",
    "1. Fine-tune SpeechT5 that was originally trained on English speech on the Dutch (nl) language subset of the VoxPopuli dataset.\n",
    "2. Use your refined model for inference in one of two ways: using a pipeline or directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c757716-8f6e-4cfe-ab7f-0af57ca12145",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c4e11-bb04-4c69-af50-207bbcb0f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets soundfile speechbrain accelerate\n",
    "\n",
    "# Install ðŸ¤—Transformers from source as not all the SpeechT5 features have been merged into an official release\n",
    "pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa3993-6be1-4a90-b121-37d4a9c55704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To follow this guide you will need a GPU\n",
    "\n",
    "# If youâ€™re working in a notebook, run the following line to check if NVIDIA GPU available\n",
    "!nvidia-smi\n",
    "\n",
    "# Or for AMD GPU\n",
    "!rocm-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf34fa1-398b-4915-ba9e-12e26fb96d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c7df51-c5be-422e-8350-80de49858a9a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0892b50-f61d-468c-98a7-92a76594f1f7",
   "metadata": {},
   "source": [
    "VoxPopuli is a large-scale multilingual speech corpus consisting of data sourced from 2009-2020 European Parliament event recordings. It contains labelled audio-transcription data for 15 European languages. In this guide, we are using the Dutch language subset, feel free to pick another subset.\n",
    "\n",
    "Note that VoxPopuli or any other automated speech recognition (ASR) dataset may not be the most suitable option for training TTS models. The features that make it beneficial for ASR, such as excessive background noise, are typically undesirable in TTS. However, finding top-quality, multilingual, and multi-speaker TTS datasets can be quite challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a23d5-ab04-4b40-a52a-ca5246d5533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "# Check len == 20968 examples\n",
    "dataset = load_dataset(\"facebook/voxpopuli\", \"nl\", split=\"train\")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bba98f-3595-41c1-a10e-1de6e02b51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpeechT5 expects audio data to have a sampling rate of 16 kHz\n",
    "# Make sure the examples in the dataset meet the requirement of 16kHz sampling rate\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4d384-32ff-4227-90f3-5fbcf7a80531",
   "metadata": {},
   "source": [
    "#Â Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9609121-b659-4a5e-b41b-86b7b3d0dbde",
   "metadata": {},
   "source": [
    "##Â Text Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f24b0f-bab1-49a7-8179-9d12bdf58c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load appropriate tokenizer and clean up text\n",
    "checkpoint = \"microsoft/speecht5_tts\"\n",
    "processor = SpeechT5Processor.from_pretrained(checkpoint)\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a32d59-ab0b-44aa-b015-f2696c56fb50",
   "metadata": {},
   "source": [
    "The dataset examples contain ```raw_text``` and ```normalized_text``` features. When deciding which feature to use as the text input, consider that the SpeechT5 tokenizer doesnâ€™t have any tokens for numbers. In ```normalized_text``` the numbers are written out as text. Thus, it is a better fit, and it is recommended to use ```normalized_text``` as input text.\n",
    "\n",
    "Because SpeechT5 was trained on the English language, it may not recognize certain characters in the Dutch dataset. If left as is, these characters will be converted to ```<unk>``` tokens. However, in Dutch, certain characters like Ã  are used to stress syllables. In order to preserve the meaning of the text, we can replace this character with a regular a.\n",
    "\n",
    "To identify unsupported tokens, extract all unique characters in the dataset using the SpeechT5Tokenizer which works with characters as tokens. To do this, write the ```extract_all_chars``` mapping function that concatenates the transcriptions from all examples into one string and converts it to a set of characters. Make sure to set ```batched=True``` and ```batch_size=-1``` in ```dataset.map()``` so that all transcriptions are available at once for the mapping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00946e-b95e-474a-88df-a2230d214a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"normalized_text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "\n",
    "vocabs = dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "\n",
    "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
    "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e11b91-89ae-49d2-be79-c6def731230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify unrecognised characters\n",
    "print(dataset_vocab - tokenizer_vocab)\n",
    "\n",
    "# Handle the unsupported characters identified in the previous step (manually in this case)\n",
    "replacements = [\n",
    "    (\"Ã \", \"a\"),\n",
    "    (\"Ã§\", \"c\"),\n",
    "    (\"Ã¨\", \"e\"),\n",
    "    (\"Ã«\", \"e\"),\n",
    "    (\"Ã­\", \"i\"),\n",
    "    (\"Ã¯\", \"i\"),\n",
    "    (\"Ã¶\", \"o\"),\n",
    "    (\"Ã¼\", \"u\"),\n",
    "]\n",
    "\n",
    "\n",
    "def cleanup_text(inputs):\n",
    "    for src, dst in replacements:\n",
    "        inputs[\"normalized_text\"] = inputs[\"normalized_text\"].replace(src, dst)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "dataset = dataset.map(cleanup_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
