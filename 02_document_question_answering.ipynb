{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19531d0d-8841-4923-b895-13069598539b",
   "metadata": {},
   "source": [
    "Document Question Answering, also referred to as Document Visual Question Answering, is a task that involves providing answers to questions posed about document images. The input to models supporting this task is typically a combination of an image and a question, and the output is an answer expressed in natural language. These models utilize multiple modalities, including text, the positions of words (bounding boxes), and the image itself.\n",
    "\n",
    "This guide illustrates how to:\n",
    "- Fine-tune LayoutLMv2 on the DocVQA dataset.\n",
    "- Use the fine-tuned model for inference.\n",
    "\n",
    "LayoutLMv2 solves the document question-answering task by adding a question-answering head on top of the final hidden states of the tokens, to predict the positions of the start and end tokens of the answer. In other words, the problem is treated as extractive question answering: given the context, extract which piece of information answers the question. The context comes from the output of an OCR engine, which is Googleâ€™s Tesseract in this particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5df9a-c87a-40e5-8473-8b009de6a3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
